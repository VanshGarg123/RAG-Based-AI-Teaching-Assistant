ğŸ¤– RAG-Based AI Teaching Assistant

> An intelligent **Retrieval-Augmented Generation (RAG)** powered AI assistant that helps users instantly find the **exact video and timestamp** where a concept is explained.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)
![RAG](https://img.shields.io/badge/Architecture-RAG-purple.svg)
![Local AI](https://img.shields.io/badge/AI-Local%20(Ollama)-orange.svg)

---

## ğŸŒŸ What Is This Project?

This project converts your **video course library into an interactive AI tutor**.

Instead of manually scrubbing through hours of video content, learners can simply ask questions in natural language, and the AI will:

- Understand the intent of the question
- Search semantically across all video transcripts
- Respond with the **most relevant video name and precise timestamp**

### ğŸ” Example Interaction

**User:**  
> How do I center a div in CSS?

**AI:**  
> This topic is covered in **Video 5 â€“ â€œCSS Basicsâ€**, starting at **03:45**, where multiple centering techniques are explained.

---

## âœ¨ Key Features

- ğŸ¯ Semantic search across entire video libraries  
- â±ï¸ Precise timestamps for instant navigation  
- ğŸ’¬ Natural chat-style user interface  
- ğŸš€ Fast vector-based retrieval using embeddings  
- ğŸ”’ Fully local and private using Ollama  
- ğŸ§  Retrieval-Augmented Generation (RAG) pipeline  
- ğŸ§© Modular design for easy extension  

---

## ğŸ“š Use Cases

- Online learning platforms  
- University lecture archives  
- Corporate training videos  
- Coaching and mentorship programs  
- Self-hosted AI learning assistants  

---

## ğŸ“‹ Prerequisites

### ğŸ”¹ Install Ollama and Required Models

```bash
# Install Ollama from https://ollama.ai/
ollama pull bge-m3      # Embedding model
ollama pull llama3.2   # Large Language Model


# Install Python dependencies
pip install flask numpy scikit-learn pandas requests joblib
```

## ğŸš€ Quick Start

### 1. Process Your Videos (One-Time Setup)

```bash
# Step 1: Add videos to videos/ folder
# Step 2: Convert to MP3
python video_to_mp3.py

# Step 3: Transcribe to JSON
python mp3_to_json.py

# Step 4: Generate embeddings
python preprocess_json.py
```

### 2. Launch the Web Interface

```bash
python app.py
```

Visit `http://localhost:5000` and start asking questions! ğŸ‰

## ğŸ—ï¸ Project Structure

```
rag-ai-assistant/
â”œâ”€â”€ videos/                 # Your video files
â”œâ”€â”€ models/
â”‚   â””â”€â”€ embeddings.joblib   # Generated vector database
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html         # Chat UI
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”œâ”€â”€ app.py                 # Flask backend
â””â”€â”€ video_to_mp3.py        # Preprocessing scripts
```

## ğŸ”§ How It Works

1. **Videos â†’ Transcripts**: Extract and timestamp audio content
2. **Transcripts â†’ Vectors**: Convert text to embeddings using BGE-M3
3. **User Question â†’ Search**: Find top 5 relevant segments using similarity
4. **Generate Response**: LLM creates natural answer with video/timestamp references

## ğŸ“ API Usage

```javascript
// POST /ask
fetch('/ask', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ question: "How do I use flexbox?" })
})
```

## ğŸ”® Future Enhancements

- Integration with **FAISS / Chroma / Qdrant**
- Multi-language transcription support
- PDF and document-based RAG
- User authentication and profiles
- Automatic video seeking to timestamps
- Streaming LLM responses
